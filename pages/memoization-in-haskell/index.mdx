---
title: Memoization of recursive functions in Haskell
subtitle: A requirement driven tutorial for the State monad
date: 2023-12-04
description: State monad 101
unlisted: true
theme: paper
layout: text
tags:
    - Haskell
---

Haskell provides a State monad, but it seems a bit too magical at times. There
are many good introductions out there that try to derive the State monad from
first principles, but they tend to focus on the "monad" part of it. Here I
approach things from a different direction: as a solution to a practical
problem.

i.e. this is the tutorial I wish I'd seen when I wanted to quickly learn how to
use state monads.

### The problem

We want to compute Fibonacci numbers. Before you start groaning, consider that
this is a great example. We already know what the function should do, so we can
focus on how to non-invasively memoizing functions that recursively call
themselves. The approach we figure out will work for many recursive functions.

Let's start with a plain version

```haskell
main :: IO ()
main = print $ fib 7

fib :: Int -> Int
fib 0 = 0
fib 1 = 1
fib n = fib (n - 1) + fib (n - 2)
```

If you want to follow along hands on, copy paste this into a file, say fib.hs,
and run it:

```sh
$ runghc fib.hs
13
```

From now I'll only mention the parts of the file that change, so you can keep
modifying the same file and re-running the `runghc fib.hs` command to see
everything play out in action.

Let us memoize this. We want to create a table where we'll store the results of
computing `fib` for a particular number, so that when we're asked to compute the
same `fib` again, we don't do all that work again.

A more realistic way of doing this would use an array or a map to store the
previous results, but I didn't want to distract from the essence of what we're
discussing here, so let us just use a normal list. Each entry in the list will
be a pair `(n, fib n)`.

Such lists are quite common indeed, they turn out to be useful in all sorts of
places, so much so that there is a name for them - they are called _associative
lists_ – and Haskell provides a function to quickly lookup a value in an
associative list. That function is already part of prelude, and guess what, it's
called `lookup`. Here is an example of it in action (this is a `ghci` prompt):

```haskell
> lookup 7 [(1, "One"), (7, "Seven")]
Just "Seven"
```

Using this, we can create our memoized Fibonacci function:

```haskell
fib :: Int -> Int
fib 0 = 0
fib 1 = 1
fib n = let (r, _) = fibmemo n [] in r

type Cache = [(Int, Int)]

fibmemo :: Int -> Cache -> (Int, Cache)
fibmemo n s = case lookup n s of
    Just v -> (v, s)
    Nothing -> let r = fib (n - 1) + fib (n - 2)
               in (r, (n, r) : s)
```

If you compile and run this, it'll still produce the correct result, but this
version is completely buggy - there is no memoization happening!

Let's take a step back at this point. In almost all other languages, adding
memoization is easy, we just plonk a global state somewhere, and we keep
updating it as our function is called. This doesn't fly in Haskell, for very
good reasons, but still it makes one wistful.

Already the memoized version in Haskell is starting to look messy, and it
doesn't even work yet! But don't despair, we'll complicate this before we're
able to make it simple again. Before enlightenment, carry wood chop water, after
enlightenment, carry wood chop water.

So we'll just (for now) get rid of our concept of a separate "pure" fibonacci
and a "memoized" layer on top - our implementation will have to mix these two
concers together. Here is a version that works:

```haskell
main :: IO ()
main = print $ runFib 7

runFib :: Int -> (Int, Cache)
runFib n = fib n []

type Cache = [(Int, Int)]

fib :: Int -> Cache -> (Int, Cache)
fib 0 s = (0, s)
fib 1 s = (1, s)
fib n s = case lookup n s of
    Just v -> (v, s)
    Nothing -> let (r1, s1) = fib (n - 1) s
                   (r2, s2) = fib (n - 2) s1
                   r = r1 + r2
               in (r, (n, r) : s)
```

Notice that we also return the Cache (which is our memo / lookup table) from the
`runFib` function. We'll eventually stop doing that and only return the result,
but it is instructive to do that for now so that we can see both the result and
the memoized values printed as we go about developing our solution.

```sh
$ runghc fib.hs
(13,[(7,13)])
```

Oh no! Our memo table is empty - it should have all the intermediate values, but
it only has the last value – `(7,13)`. Is our memoization still not working?

Turns out there is a small typo in the last line. `(r, (n, r) : s)` should be
`(r, (n, r) : s2)`. Here is the fixed version of `fib`:

```haskell
fib :: Int -> Cache -> (Int, Cache)
fib 0 s = (0, s)
fib 1 s = (1, s)
fib n s = case lookup n s of
    Just v -> (v, s)
    Nothing -> let (r1, s1) = fib (n - 1) s
                   (r2, s2) = fib (n - 2) s1
                   r = r1 + r2
               in (r, (n, r) : s2)
```

And if we run this again, we'll see that all intermediate entries are also
present in our memoized table:

```sh
$ runghc fib.hs
(13,[(7,13),(6,8),(5,5),(4,3),(3,2),(2,1)])
```

This typo demonstrates how finicky and error prone it is to manually pass this
state around. It gets worse with recursive functions, because we might not
thread the state along one of the code paths accidentally, and everything will
still work, just be dog slow.

Back to work. So what we've done here that instead of letting `fib` be a
function that takes an `Int` and returns an `Int`, we have made it into a
function that takes an `Int` and a `Cache`, and returns an both the result `Int`
and (possibly) modified `Cache` so that we can pass that along. Written as
types, we have:

```haskell
fib :: Int -> Cache -> (Int, Cache)
```

But the beauty of Haskell is that this same function signature can be
interpreted in another way – `fib` is a function that takes an `Int`, and it
returns a new function `Cache -> (Int, Cache)`.

One thing that you might think here is that - shouldn't the arguments be the
other way around? As in, how about if we'd written `fib` this way:

```haskell
fib :: Cache -> Int -> (Int, Cache)
```

We can even argue that this would make more logical sense. However, notice what
happens if we want to memoize some two argument function, say `plus`, in the
future. If we'd done it in that hypothetically flipped way, it's type would look
like:

```haskell
plus :: Cache -> Int -> Int -> (Int, Cache)
```

In the way we're following, it's type would be

```haskell
plus :: Int -> Int -> Cache -> (Int, Cache)
```

Notice how the trailing part of the type is the same! As in, keeping the state
last means that we always return a `Cache -> (Int, Cache)`, no matter how many
arguments the original function that we're memoizing takes.

You might say that what if we want to memoize a function that returns something
other than a `Int`, or whose memo table has a different type like a `Map`? Easy
peasy, we can actually just parameterize these two types:

-  Let us call the type of the state as `s`.

-  Let us call the result type as `a`.

So we end up with this pattern - any function that we want to memoize will take
as many arguments, and of varying types, as it needs. The only requirement we
place is that it should return a function of type `s -> (a, s)`.

Such functions `s -> (a, s)` are called the **State monad**. But we're getting
ahead of ourselves with the "monad" part, forget that I said the m-word.

Let us just talk about values of type `s -> (a, s)`. Trust me with this, and
you'll see soon, that if we follow this convention – that any function that we
want to memoize should return another function `s -> (a, s)` – then it will
become easy to compose them.

So that everyone doesn't go around definining their own typedefs and helper
functions around this, the Haskell standard installation ships with this
predefined. It is called a `State` and is defined in the `Control.Monad.State`
module.

> Note that the word "state" here refers to two different things. In general,
> state refers to anything that we want to automatically thread along our normal
> functions. The type `State` (capitalized one) is actually a shorthand for the
> "State monad".
>
> That is, the type `s -> (a, s)` is the "State monad" (and the Haskell type
> that refers to a "State monad" is called `State`). This type itself has two
> parameters - `s` and `a`. It is this lowercase `s` which is the actual state.
>
> Don't worry if this is confusing, that's why I kept this difference as an
> aside. It'll become clear once we complete our example.

So let us modify our code to use the standard library types:

```haskell
import Control.Monad.State

main :: IO ()
main = print $ runFib 7

runFib :: Int -> (Int, Cache)
runFib n = (fib n) []

type Cache = [(Int, Int)]

fib :: Int -> State Cache Int
fib 0 = \s -> (0, s)
fib 1 = \s -> (1, s)
fib n = \s ->
    case lookup n s of
      Just v -> (v, s)
      Nothing -> let (r1, s1) = (fib (n - 1)) s
                     (r2, s2) = (fib (n - 2)) s1
                     r = r1 + r2
                 in (r, (n, r) : s2)
```

Remember, `State s a` (essentially) means `s -> (a, s)`. So we've changed the
type of `fib` from `Int -> Cache -> (Int, Cache)` to `Int -> State Cache Int`.
And it's implementation is changed from, say, `fib 0 s = (0, s)` to
`fib 0 = \s -> (0, s)` to highlight that it is actually returning a function.

This doesn't actually compile though. When I said that `State s a` essentially
means `s -> (a, s)`, I didn't lie, but there is a stress on _essentially_.
Because the actual type of `State` is a bit more complicated (for reasons that
have nothing to do with what we're discussing here). To get this to compile, we
have to make a few changes:

1. Wrap the returned functions in a `StateT`.
2. Wrap the returned values from these functions in an `Identity` (this'll also
   require adding an `import Control.Monad.Identity` at the top).
3. Wrap all calls to these functions in `runState`.

> Don't despair if this is not making sense. It won't necessarily. Rememeber,
> it'll get complicated before it gets simple again. The reason it is getting so
> complicated in the middle is that this is not the way the state monad is used
> in practice, but to get to the simple way we'll need to wait till the end of
> this post.

Here is the fixed up code:

```haskell
import Control.Monad.State
import Control.Monad.Identity

main :: IO ()
main = print $ runFib 7

runFib :: Int -> (Int, Cache)
runFib n = runState (fib n) []

type Cache = [(Int, Int)]

fib :: Int -> State Cache Int
fib 0 = StateT $ \s -> Identity (0, s)
fib 1 = StateT $ \s -> Identity (1, s)
fib n = StateT $ \s ->
    case lookup n s of
      Just v -> Identity (v, s)
      Nothing -> let (r1, s1) = runState (fib (n - 1)) s
                     (r2, s2) = runState (fib (n - 2)) s1
                     r = r1 + r2
                 in Identity (r, (n, r) : s2)
```

We can now run this, and it'll give the result we expect.

```sh
$ runghc fib.hs
(13,[(7,13),(6,8),(5,5),(4,3),(3,2),(2,1)])
```

Alright, let us start simplifying this!

### Monads!

Remember, "State" is a "monad". You don't need to really understand monads to
follow along what's going to happen next - the tl;dr; you can keep in mind is
that if something is a monad, then there are special functions that we can use
to compose values of such types.

The first such function is `pure`. It represents the "simplest" version of a
particular value. In our case, what is the simplest value of type `s -> (a, s)`.
Well, it just needs to return the `a` and not twiddle with the state. But how do
we get an `a`? We pass it to `pure`!

```haskell
-- Snipped for illustrative purposes
pure x = \s -> (x, s)
```

We can use `pure` to simplify the first two clauses of our function definition.

```haskell
fib 0 = pure 0
fib 1 = pure 1
```

If we run the code again after making that change, it'll still give the same
result. That's weird, where did all the surrounding junk go!

It might seem like magic, or something that has a special case in the compiler,
but no, this is all a library level abstraction. Haskell is a gift that'll keep
giving.

Let's continue.

