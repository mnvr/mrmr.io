---
title: RLHF & leftâ€¢right brains
date: 2023-09-21
layout: blog
description: RLHF used in LLMs is like the left/right brain split in humans
---

import { Footer, Title, MarginQuote } from "./index.tsx";

<Title />

The title of the post is really all I have to say. There is an interesting,
perhaps even illuminating, analogy between how we've ended up with a RLHF
control process overseeing raw LLMs and how our own brains (potentially) work.

The rest of this post is an attempt to lay out this analogy in more detail so
that people who might not have the relevant lore can also see the connection I'm
pointing at. I'll simplify things a bit, maybe too much at places, to keep the
post short.

If you already see the connection, then there's nothing more to see here. If you
already see the connection but think it is trite / silly, oh well, maybe it is
just an imperfect analogy.

---

<MarginQuote>Men create god in their own image</MarginQuote>

RLHF (Reinforcement Learning from Human Feedback) is a mechanism used by current
state of the art LLMs (Large Language Models), e.g. ChatGPT.

<Footer />
